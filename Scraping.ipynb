{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Scraping Data from Amazon using the special code which amazon assigns it to the products called as ASIN number. It can be easily found on the product page in Product details scetion or in the product site url."
      ],
      "metadata": {
        "id": "1NABes_VmT-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using Beautifulsoup, Pandas and Requests library from python"
      ],
      "metadata": {
        "id": "jzCvuaWAmzMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NgBsA07Kmy57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
        "reviewList = []\n",
        "prodId = 1"
      ],
      "metadata": {
        "id": "2xIDYgSEvj5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSoup(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
        "    page = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "# this function extracts the review data from a given soup data\n",
        "def getReviews(soup):\n",
        "    global prodId\n",
        "    reviews = soup.find_all('div', {'data-hook':'review'})\n",
        "    \n",
        "    try:\n",
        "        for item in reviews:\n",
        "            review = {\n",
        "                'Id': prodId,\n",
        "                'reviewTitle': item.find('a', {'data-hook':'review-title'}).text.strip(),\n",
        "                'rating': item.find('i', {'data-hook':'review-star-rating'}).text.replace('out of 5 stars','').strip(),\n",
        "                'reviewText': item.find('span', {'data-hook':'review-body'}).text.replace('\\n',' ').strip()\n",
        "            }\n",
        "            prodId += 1\n",
        "            reviewList.append(review)\n",
        "    except:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "z9CjgYedvsVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  asin = input('Enter ASIN number of product: ')\n",
        "\n",
        "  x = 1\n",
        "  url = f'https://www.amazon.in/product-reviews/{asin}/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber={x}'\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
        "  page = requests.get(url, headers=headers)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "  # find the element containing the average rating and extract the rating value\n",
        "  avg_rating_elem = soup.find('span', {'data-hook': 'rating-out-of-text'})\n",
        "  avg_rating = avg_rating_elem.text.strip()\n",
        "\n",
        "  # print the average rating\n",
        "  print(f'Average customer rating: {avg_rating}')\n",
        "  soup = getSoup(url)\n",
        "  productName = soup.find('a', {'data-hook':'product-link'}).text.strip()\n",
        "  print(f'Product: {productName}')\n",
        "\n",
        "  # getting recent reviews from all the review pages\n",
        "  for x in range(1,10):\n",
        "      soup = getSoup(f'https://www.amazon.in/product-reviews/{asin}/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber={x}')\n",
        "      print(f'Getting review page {x}...')\n",
        "      getReviews(soup)\n",
        "      if soup.find('li', {'class':'a-disabled a-last'}):\n",
        "          break \n",
        "      else:\n",
        "          pass\n",
        "    \n",
        "\n",
        "  # converting list into a dataframe    \n",
        "  df = pd.DataFrame(reviewList)\n",
        "\n",
        "  # converting dataframe to an excel sheet\n",
        "  print('Converting to .xlsx ...')\n",
        "  df.to_excel(asin+'-reviews.xlsx', index=False)\n",
        "  print('Review extraction finished! extracted to file ' + asin +'-review.xlsx :)')"
      ],
      "metadata": {
        "id": "7jGX-vYFvzMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__== '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqoLqaCewFep",
        "outputId": "70b74987-3a9c-4ced-88e4-e0ac4d1719e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter ASIN number of product: B01J0XWYKQ\n",
            "Average customer rating: 4.4 out of 5\n",
            "Product: Logitech B170 Wireless Mouse, 2.4 GHz with USB Nano Receiver, Optical Tracking, 12-Months Battery Life, Ambidextrous, PC/Mac/Laptop - Black\n",
            "Getting review page 1...\n",
            "Getting review page 2...\n",
            "Getting review page 3...\n",
            "Getting review page 4...\n",
            "Getting review page 5...\n",
            "Getting review page 6...\n",
            "Getting review page 7...\n",
            "Getting review page 8...\n",
            "Getting review page 9...\n",
            "Converting to .xlsx ...\n",
            "Review extraction finished! extracted to file B01J0XWYKQ-review.xlsx :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvVRvW0twSY0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}